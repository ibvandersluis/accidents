predict.regsubsets = function(object, newdata, id, ...){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi = coef(object, id=id)
xvars = names(coefi)
mat[,xvars]%*%coefi
}
# Get best model with cross validation approach
set.seed(42)
k=10
rm(k)
rm(predict.regsubsets())
rm(predict.regsubsets())
View(predict.regsubsets)
# Export CSV of prepared data
write.csv(accidents, "prep.csv", row.names = F)
# Export as dataframe that keeps formatting
saveRDS(accidents, file="prep.rds")
# Save history
savehistory()
# Clear workspace
rm(list=ls())
# Load data
accidents = readRDS("prep.rds")
attach(accidents)
summary(fatal)
table(fatal)
str(accidents)
# Create test set
# Get random sample to test on
set.seed(42)
testRows = sample(1:nrow(accidents), 0.1*nrow(accidents))
train = accidents[-testRows,]
test = accidents[testRows,]
# Fit multiple logistic regression
lm.fit = lm(fatal ~ ., data = train)
summary(lm.fit)
lm.preds = predict(lm.fit, test)
results = data.frame(cbind(actuals=test, predicteds=lm.preds))
table(results)
cor(results)
# Clear workspace
rm(list=ls())
# Load data
accidents = readRDS("prep.rds")
summary(accidents)
# Scale the data except for the qualitative response variable
scaled = scale(accidents[, -26])
var(accidents[,1])
var(accidents[,2])
var(scaled[,1])
var(scaled[,2])
fix(scaled)
# Export as dataframe that keeps formatting
saveRDS(accidents, file="prep.rds", row.names = F)
# Create test set
# Get random sample to test on
set.seed(42)
testRows = sample(1:nrow(accidents), 0.1*nrow(accidents))
accidents.train = accidents[-testRows,]
accidents.test = accidents[testRows,]
fatal.test = fatal[testRows]
rm(accidents.test, accidents.train)
attach(accidents)
train.X = scaled[-testRows,]
test.X = scaled[testRows,]
train.Y = fatal[-testRows]
test.Y = fatal[testRows]
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
# Load library
library(class)
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
is.na(accidents)
sum(is.na(accidents))
na.omit(accidents)
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
# Scale the data except for the qualitative response variable
scaled = scale(accidents[, -26])
train.X = scaled[-testRows,]
test.X = scaled[testRows,]
train.Y = fatal[-testRows]
test.Y = fatal[testRows]
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
sum(is.na(accidents))
na.omit(accidents)
na.omit(train.X)
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
na.omit(train.Y)
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
na.omit(test.x)
na.omit(test.X)
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
sum(is.na(accidents))
na.omit(train.X)
na.omit(train.Y)
na.omit(test.X)
sum(is.na(train.X))
sum(is.na(train.Y))
# Clear workspace
rm(list=ls())
# Load data
accidents = read.csv("accidents.csv", header = T, na.strings = "-1")
# Inspect data
dim(accidents)
names(accidents)
# Inspect fatality data (accident is fatal if accident_severity = 1)
table(accidents$accident_severity)
# Create 'Fatal' variable
accidents$fatal = 0
names(accidents)
# Set 'fatal' to 1 if there was a fatality
accidents$fatal[accidents$accident_severity == 1] = 1
# Check that number of fatal = 1 is the same as what we get from accident_severity
table(accidents$fatal)
table(accidents$fatal, accidents$accident_severity)
# Get fatality percentages
prop.table(table(accidents$fatal))
# Remove unwanted variables
accidents$accident_severity = NULL
accidents$police_force = NULL
accidents$local_authority_.district. = NULL
accidents$local_authority_.highway. = NULL
accidents$car_passenger = NULL
accidents$bus_or_coach_passenger = NULL
accidents$pedestrian_road_maintenance_worker = NULL
accidents$location_easting_osgr = NULL
accidents$location_northing_osgr = NULL
accidents$latitude = NULL
accidents$longitude = NULL
accidents$lsoa_of_accident_location = NULL
accidents$did_police_officer_attend_scene_of_accident = NULL
accidents$sex_of_casualty = NULL
accidents$casualty_class = NULL
accidents$age_of_casualty = NULL
accidents$age_band_of_casualty = NULL
accidents$casualty_type = NULL
accidents$number_of_casualties = NULL
accidents$NUmber_of_Casualities_unique_to_accident_index = NULL
accidents$X1st_road_number = NULL
accidents$X2nd_road_number = NULL
accidents$casualty_reference = NULL
accidents$casualty_severity = NULL
accidents$casualty_home_area_type = NULL
accidents$casualty_imd_decile = NULL
accidents$accident_index = NULL
accidents$vehicle_reference = NULL
# Check if variance of feature includes fatality
table(accidents$speed_limit, accidents$fatal)
table(accidents$towing_and_articulation, accidents$fatal)
table(accidents$pedestrian_crossing.human_control, accidents$fatal)
table(accidents$pedestrian_location, accidents$fatal)
table(accidents$pedestrian_movement, accidents$fatal)
table(accidents$junction_detail, accidents$fatal)
table(accidents$propulsion_code, accidents$fatal)
table(accidents$skidding_and_overturning, accidents$fatal)
table(accidents$was_vehicle_left_hand_drive., accidents$fatal)
table(accidents$number_of_vehicles, accidents$fatal)
table(accidents$urban_or_rural_area, accidents$fatal)
prop.table(table(accidents$urban_or_rural_area, accidents$fatal))
table(accidents$driver_imd_decile, accidents$fatal)
summary(accidents$driver_imd_decile)
# The feature driver_imd_decile is entirely empty and can be removed
accidents$driver_imd_decile = NULL
table(accidents$vehicle_imd_decile, accidents$fatal)
# vehicle_imd_decile is also empty and can be removed
accidents$vehicle_imd_decile = NULL
table(accidents$No_of_Vehicles_involved_unique_to_accident_index, accidents$number_of_vehicles)
# No_of_Vehicles_involved_unique_to_accident_index is identical to numer_of_vehicles and can be removed
accidents$No_of_Vehicles_involved_unique_to_accident_index = NULL
# Remove junk data from 'time' variable
accidents$time = substring(accidents$time, first = 12)
# The 'date' variable either shows a date in 2015 or an integer in the 40,000 range
# Unfortunately this means it cannot be relied upon for any useful information
# Remove date
accidents$date = NULL
# Remove NA rows
sum(is.na(accidents))
accidents = na.omit(accidents)
# Remove NA rows
sum(is.na(accidents))
str(accidents)
# Convert boolean response variable to logical
# accidents$fatal = as.logical(accidents$fatal)
accidents$fatal = as.integer(accidents$fatal)
# Convert $pedestrian_location and $pedestrian_movement to numerical
accidents$pedestrian_location = as.integer(accidents$pedestrian_location)
accidents$pedestrian_movement = as.integer(accidents$pedestrian_movement)
# Convert time
library(chron)
accidents$time = chron(times=accidents$time)
# Check data again
str(accidents)
# All features are numeric, check for significance of variables and if we can remove any
# Inpect correlations
cor(accidents)
# Remove NA rows
sum(is.na(accidents))
accidents = na.omit(accidents)
# All features are numeric, check for significance of variables and if we can remove any
# Inpect correlations
cor(accidents)
# Fit linear model
lm.fit = lm(fatal ~ ., data = accidents)
summary(lm.fit)
# Remove features with p-value > 0.05
accidents$carriageway_hazards = NULL
accidents$special_conditions_at_site = NULL
accidents$weather_conditions = NULL
accidents$pedestrian_crossing.human_control = NULL
accidents$age_band_of_driver = NULL
accidents$road_type = NULL
accidents$number_of_vehicles = NULL
accidents$driver_home_area_type = NULL
accidents$age_of_vehicle = NULL
accidents$propulsion_code = NULL
accidents$X1st_point_of_impact = NULL
accidents$was_vehicle_left_hand_drive. = NULL
# accidents$hit_object_off_carriageway = NULL
# Refit and check p-values again
lm.fit = lm(fatal ~ ., data = accidents)
summary(lm.fit)
# Remove features with p-value > 0.05
accidents$vehicle_type = NULL
# accidents$towing_and_articulation = NULL
# Check again
lm.fit = lm(fatal ~ ., data = accidents)
summary(lm.fit)
# Perform best subsets selection
library(leaps)
regfit.full = regsubsets(fatal ~ ., accidents, nvmax=25)
reg.summary= summary(regfit.full)
reg.summary$rsq
# Plot RSS
plot(reg.summary$rss, xlab="Number of Variables", ylab="RSS", type="l")
# Plot Adjusted Rsq
plot(reg.summary$adjr2, xlab="Number of Variables", ylab="Adjusted RSq", type="l")
which.max(reg.summary$adjr2)
points(25, reg.summary$adjr2[25], col="red", cex=2, pch=20)
# Plot Cp
plot(reg.summary$cp, xlab="Number of Variables", ylab="Cp", type="l")
which.min(reg.summary$cp)
points(25, reg.summary$cp[25], col="red", cex=2, pch=20)
# Plot BIC
plot(reg.summary$bic, xlab="Number of Variables", ylab="BIC", type="l")
which.min(reg.summary$bic)
points(17, reg.summary$bic[17], col="red", cex=2, pch=20)
plot(regfit.full, scale="r2")
plot(regfit.full, scale="adjr2")
plot(regfit.full, scale="Cp")
plot(regfit.full, scale="bic")
# Export CSV of prepared data
write.csv(accidents, "prep.csv", row.names = F)
# Export as dataframe that keeps formatting
saveRDS(accidents, file="prep.rds")
# Save history
savehistory()
# Clear workspace
rm(list=ls())
# Load library
library(class)
# Load data
accidents = readRDS("prep.rds")
summary(accidents)
attach(accidents)
# Scale the data except for the qualitative response variable
scaled = scale(accidents[, -26])
var(accidents[,1])
var(accidents[,2])
var(scaled[,1])
var(scaled[,2])
# Create test set
# Get random sample to test on
set.seed(42)
testRows = sample(1:nrow(accidents), 0.1*nrow(accidents))
train.X = scaled[-testRows,]
test.X = scaled[testRows,]
train.Y = fatal[-testRows]
test.Y = fatal[testRows]
# Fit kNN model
knn.pred = knn(train.X, test.X, train.Y, k=1)
mean(test.Y != knn.pred)
mean(test.Y != 0)
table(knn.pred, fatal)
table(knn.pred, test.Y)
24/(24 + 49)
# Refit with k=3
knn.pred = knn(train.X, test.X, train.Y, k=3)
mean(test.Y != knn.pred)
mean(test.Y != 0)
# Lower test error than k=1
mean(test.Y != 0)
table(knn.pred, test.Y)
12/(12 + 61)
# Refit with k=5
knn.pred = knn(train.X, test.X, train.Y, k=5)
mean(test.Y != knn.pred)
mean(test.Y != 0)
table(knn.pred, test.Y)
# Our accuracy is amazing-ish, but we
6/(6 + 67)
# Refit with k=7
knn.pred = knn(train.X, test.X, train.Y, k=7)
mean(test.Y != knn.pred)
# Incredibly low test error, probably means it barely predicted any crashes
mean(test.Y != 0)
table(knn.pred, test.Y)
3/(3 + 70)
# Save history
savehistory()
# Clear workspace
rm(list=ls())
# Load data
accidents = readRDS("prep.rds")
attach(accidents)
summary(accidents)
# Create test set
# Get random sample to test on
set.seed(42)
testRows = sample(1:nrow(accidents), 0.1*nrow(accidents))
accidents.train = accidents[-testRows,]
accidents.test = accidents[testRows,]
fatal.test = fatal[testRows]
# Fit logistic regression model
glm.fit = glm(fatal ~ ., data=accidents, family=binomial, subset=-testRows)
glm.probs = predict(glm.fit, accidents.test, type="response")
glm.preds = rep(0,10132)
glm.preds[glm.probs>.5] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.4
glm.preds[glm.probs>.4] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.3
glm.preds[glm.probs>.3] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.2
glm.preds[glm.probs>.2] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.1
glm.preds[glm.probs>.1] = 1
table(glm.preds, fatal.test)
table(glm.preds, fatal.test)
# Try with threshold = 0.05
glm.preds[glm.probs>.05] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.5
glm.preds = rep(0,10132)
glm.preds[glm.probs>.5] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.3
glm.preds = rep(0,10132)
glm.preds[glm.probs>.3] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.2
glm.preds = rep(0,10132)
glm.preds[glm.probs>.2] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.1
glm.preds = rep(0,10132)
glm.preds[glm.probs>.1] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.05
glm.preds = rep(0,10132)
glm.preds[glm.probs>.05] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.05
glm.preds = rep(0,10132)
glm.preds[glm.probs>.04] = 1
table(glm.preds, fatal.test)
glm.preds[glm.probs>.03] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.02
glm.preds = rep(0,10132)
glm.preds[glm.probs>.02] = 1
table(glm.preds, fatal.test)
# We successfully predict 30 of 71 fatal accidents
# With a lot of incorrect predictions as well...
# Predict 695, of which 30 are correct
30/(30 + 665)
# Try with threshold = 0.01
glm.preds = rep(0,10132)
glm.preds[glm.probs>.01] = 1
table(glm.preds, fatal.test)
41/(1794 + 41)
# Try with threshold = 0.009
glm.preds = rep(0,10132)
glm.preds[glm.probs>.009] = 1
table(glm.preds, fatal.test)
44/(44 + 2053)
# 2% accuracy
# Try with threshold = 0.007
glm.preds = rep(0,10132)
glm.preds[glm.probs>.007] = 1
table(glm.preds, fatal.test)
# Try with threshold = 0.007
glm.preds = rep(0,10132)
glm.preds[glm.probs>.005] = 1
table(glm.preds, fatal.test)
glm.preds[glm.probs>.002] = 1
table(glm.preds, fatal.test)
# Save history
savehistory()
# Clear workspace
rm(list=ls())
# Load tree library
library(tree)
# Load data
accidents = readRDS("prep.rds")
str(accidents)
attach(accidents)
# Make response variable logical
accidents$fatal = as.factor(accidents$fatal)
str(accidents)
# Turning variables into factors improves misclassification rate
accidents$towing_and_articulation = as.factor(accidents$towing_and_articulation)
accidents$vehicle_manoeuvre = as.factor(accidents$vehicle_manoeuvre)
accidents$vehicle_location.restricted_lane = as.factor(accidents$vehicle_location.restricted_lane)
accidents$junction_location = as.factor(accidents$junction_location)
accidents$skidding_and_overturning = as.factor(accidents$skidding_and_overturning)
accidents$hit_object_in_carriageway = as.factor(accidents$hit_object_in_carriageway)
accidents$vehicle_leaving_carriageway = as.factor(accidents$vehicle_leaving_carriageway)
accidents$hit_object_off_carriageway = as.factor(accidents$hit_object_off_carriageway)
accidents$journey_purpose_of_driver = as.factor(accidents$journey_purpose_of_driver)
accidents$sex_of_driver = as.factor(accidents$sex_of_driver)
accidents$day_of_week = as.factor(accidents$day_of_week)
accidents$X1st_road_class = as.factor(accidents$X1st_road_class)
accidents$junction_detail = as.factor(accidents$junction_detail)
accidents$junction_control = as.factor(accidents$junction_control)
accidents$X2nd_road_class = as.factor(accidents$X2nd_road_class)
accidents$pedestrian_crossing.physical_facilities = as.factor(accidents$pedestrian_crossing.physical_facilities)
accidents$light_conditions = as.factor(accidents$light_conditions)
accidents$road_surface_conditions = as.factor(accidents$road_surface_conditions)
accidents$urban_or_rural_area = as.factor(accidents$urban_or_rural_area)
accidents$pedestrian_location = as.factor(accidents$pedestrian_location)
accidents$pedestrian_movement = as.factor(accidents$pedestrian_movement)
str(accidents)
# Create test set
# Get random sample to test on
set.seed(42)
testRows = sample(1:nrow(accidents), 0.1*nrow(accidents))
accidents.train = accidents[-testRows,]
accidents.test = accidents[testRows,]
fatal.test = fatal[testRows]
# Fit classification tree
tree.accidents = tree(fatal ~ ., accidents.train, control=tree.control(nobs=91192, mindev=0.0008))
tree.preds = predict(tree.accidents, accidents.test, type="class")
table(tree.preds, fatal.test)
summary(tree.accidents)
# Implement pruning
set.seed(1)
cv.accidents = cv.tree(tree.accidents)
names(cv.accidents)
cv.accidents
# Try bagging
library(randomForest)
set.seed(1)
?randmForest
?randomForest()
# Fit classification tree
tree.accidents = tree(fatal ~ ., accidents[-testRows], control=tree.control(nobs=91192, mindev=0.0008))
# Fit classification tree
tree.accidents = tree(fatal ~ ., accidents[-testRows,], control=tree.control(nobs=91192, mindev=0.0008))
# Fit classification tree
tree.accidents = tree(fatal ~ ., accidents, subset=-testRows, control=tree.control(nobs=91192, mindev=0.0008))
tree.preds = predict(tree.accidents, accidents.test, type="class")
table(tree.preds, fatal.test)
summary(tree.accidents)
plot(tree.accidents)
# Implement pruning - doesn't work
set.seed(1)
cv.accidents = cv.tree(tree.accidents)
names(cv.accidents)
cv.accidents
cv.accidents = cv.tree(tree.accidents, FUN=prune.misclass)
names(cv.accidents)
cv.accidents
# Try bagging
library(randomForest)
set.seed(1)
?randomForest()
bag.accidents = randomForest(fatal ~ ., data=accidents.train, mtry=25, importance=T)
writeRDS(bag.accidents, "bag_accidents.rds")
saveRDS(bag.accidents, "bag_accidents.rds")
bag.accidents
yhat.bag = predict(bag.accidents, newdata=accidents.test)
plot(yhat.bag, fatal.test)
plot(yhat.bag, accidents.test)
table(yhat.bag, fatal.test)
# Try random forest
set.seed(1)
rf.accidents = randomForest(fatal ~ ., data=accidents.train, mtry=12, importance=T)
yhat.rf = predict(rf.accidents, newdata=accidents.test)
table(yhat.rf, fatal.test)
importance(rf.accidents)
plot(importance(rf.accidents))
varImpPlot(rf.accidents)
saveRDS(rf.accidents, "rf_accidents.rds")
# Try boosting
library(gbm)
set.seed(1)
boost.accidents = gbm(fatal ~ ., data=accidents.train, distribution="bernoulli", n.trees=1000, interaction.depth=9)
summary(boost.accidents)
summary(boost.accidents)
yhat.boost = predict(boost.accidents, newdata=accidents.test, ntrees=1000)
yhat.boost = predict(boost.accidents, newdata=accidents.test, n.trees=1000)
table(yhat.boost, fatal.test)
